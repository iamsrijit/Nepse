# -*- coding: utf-8 -*-
"""New_espen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DY-Qa-RUQOkqYaYjmP5_rq894DO-OYiP
"""

# -*- coding: utf-8 -*-
"""Quantum Analysis with GitHub Integration"""
import pandas as pd
import numpy as np
import requests
import base64
import io
import os
from datetime import datetime
from scipy.stats import linregress
from xgboost import XGBRegressor
from sklearn.model_selection import TimeSeriesSplit

# ========================
# Configuration
# ========================
GITHUB_TOKEN = os.environ.get('GH_TOKEN')  # From environment variables
REPO_OWNER = "iamsrijit"
REPO_NAME = "Nepse"

# ========================
# GitHub Integration
# ========================
class GitHubDataHandler:
    def __init__(self, token):
        if not token:
            raise ValueError("GitHub token not found in environment variables")

        self.token = token
        self.headers = {'Authorization': f'token {self.token}'}
        self.base_url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}"

    def get_latest_espen(self):
        """Retrieve latest merged data file"""
        try:
            contents_url = f"{self.base_url}/contents"
            response = requests.get(contents_url, headers=self.headers)
            response.raise_for_status()
            files = response.json()

            espen_files = [f for f in files if f['name'].startswith('espen_')]
            dates = [datetime.strptime(f['name'][6:-4], "%Y-%m-%d") for f in espen_files]
            latest_file = espen_files[dates.index(max(dates))]

            response = requests.get(latest_file['download_url'])
            return pd.read_csv(io.StringIO(response.text))
        except Exception as e:
            print(f"Data fetch error: {str(e)}")
            return pd.DataFrame()

    def upload_results(self, content):
        """Upload analysis results to GitHub"""
        try:
            filename = f"Analysis_{datetime.now().strftime('%Y-%m-%d')}.txt"
            url = f"{self.base_url}/contents/{filename}"
            data = {
                "message": f"Add analysis results {filename}",
                "content": base64.b64encode(content.encode()).decode(),
                "branch": "main"
            }
            response = requests.put(url, headers=self.headers, json=data)
            return response.status_code in (200, 201)
        except Exception as e:
            print(f"Upload error: {str(e)}")
            return False

# ========================
# Quantum Analysis
# ========================
class QuantumAnalyzer:
    def __init__(self):
        self.model = XGBRegressor(objective='reg:squarederror')

    def _calculate_features(self, group):
        """Feature engineering for ML"""
        close_prices = group['Close'].values
        returns = np.log(close_prices[1:]/close_prices[:-1])

        return {
            'Einstein_Momentum': linregress(np.arange(len(close_prices)), close_prices).slope * 100,
            'Spacetime_Curvature': np.polyfit(np.arange(len(close_prices)), close_prices, 2)[0] * 1e4,
            'Price_Change%': ((close_prices[-1]/close_prices[0]-1)*100)
        }

    def analyze(self, df):
        """Perform analysis on GitHub data"""
        results = []
        grouped = df.groupby('Symbol', sort=False)

        for symbol, group in grouped:
            if len(group) < 100:
                continue

            try:
                features = self._calculate_features(group)
                results.append({
                    **features,
                    'Symbol': symbol
                })
            except Exception as e:
                print(f"Skipped {symbol}: {str(e)}")

        return pd.DataFrame(results).sort_values('Einstein_Momentum', ascending=False)

    def generate_portfolio(self, results):
        """Generate portfolio allocation"""
        portfolio = []
        allocations = {'Core': 45, 'Growth': 30, 'Speculative': 20, 'Cash': 5}

        # Core pick (highest momentum)
        core = results.nlargest(1, 'Einstein_Momentum').iloc[0]
        portfolio.append({
            'Symbol': core['Symbol'],
            'Allocation': f"{allocations['Core']}%",
            'Rationale': f"Core: Momentum={core['Einstein_Momentum']:.1f}% + Curvature"
        })

        # Growth pick (highest returns)
        growth = results.nlargest(1, 'Price_Change%').iloc[0]
        portfolio.append({
            'Symbol': growth['Symbol'],
            'Allocation': f"{allocations['Growth']}%",
            'Rationale': f"Growth: Returns={growth['Price_Change%']:.1f}%"
        })

        # Speculative pick (mid-range momentum)
        mid_momentum = results[results['Einstein_Momentum'].between(-5, 5)]
        if not mid_momentum.empty:
            spec = mid_momentum.nlargest(1, 'Price_Change%').iloc[0]
            portfolio.append({
                'Symbol': spec['Symbol'],
                'Allocation': f"{allocations['Speculative']}%",
                'Rationale': f"Speculative: Momentum={spec['Einstein_Momentum']:.1f}%"
            })

        # Cash allocation
        portfolio.append({
            'Symbol': 'Cash',
            'Allocation': f"{allocations['Cash']}%",
            'Rationale': 'Market buffer'
        })

        return pd.DataFrame(portfolio)

# ========================
# Execution Pipeline
# ========================
def main():
    # Initialize components
    gh = GitHubDataHandler(GITHUB_TOKEN)
    analyzer = QuantumAnalyzer()

    print("=== Starting Analysis ===")

    # Step 1: Get data from GitHub
    print("\n[1/3] Fetching latest data...")
    df = gh.get_latest_espen()
    if df.empty:
        print("No data available")
        return

    # Step 2: Perform analysis
    print("\n[2/3] Running quantum analysis...")
    results = analyzer.analyze(df)
    portfolio = analyzer.generate_portfolio(results)

    # Step 3: Format output
    output = "=== Analysis Results ===\n"
    output += results[['Symbol', 'Einstein_Momentum', 'Spacetime_Curvature', 'Price_Change%']].to_string(index=False)
    output += "\n\n=== Dynamic Portfolio ===\n"
    output += portfolio.to_string(index=False)

    # Step 4: Upload results
    print("\n[3/3] Uploading results...")
    if gh.upload_results(output):
        print("\n✅ Analysis uploaded successfully")
    else:
        print("\n⚠️ Upload failed")

if __name__ == "__main__":
    main()