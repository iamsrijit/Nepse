# Install necessary libraries if not available # !pip install pandas numpy requests import pandas as pd import numpy as np import requests import base64 from datetime import datetime # ============================================================================ # CONFIGURATION # ============================================================================ REPO_OWNER = 'iamsrijit' REPO_NAME = 'Nepse' BRANCH = 'main' GITHUB_TOKEN = None # Set your GitHub token here if needed for private repos or higher rate limits # Headers for GitHub API HEADERS = { 'Accept': 'application/vnd.github.v3+json' } if GITHUB_TOKEN: HEADERS['Authorization'] = f'token {GITHUB_TOKEN}' # Trading parameters STARTING_CAPITAL = 500000 # â‚¹5,00,000 RISK_PER_TRADE = 0.01 # 1% risk per trade ATR_PERIOD = 14 SMA_PERIOD = 50 VOLUME_PERIOD = 20 VOLUME_MULTIPLIER = 1.2 MAX_RECENT_DRAWDOWN = -0.05 # 5% max drawdown threshold STOP_LOSS_ATR_MULTIPLIER = 2 # ============================================================================ # GITHUB UTILITY FUNCTIONS # ============================================================================ def github_raw(path): """Generate raw GitHub URL for a file""" return f"https://raw.githubusercontent.com/{REPO_OWNER}/{REPO_NAME}/{BRANCH}/{path}" def upload_to_github(filename, content): """Upload or overwrite a file in GitHub repository""" url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{filename}" r = requests.get(url, headers=HEADERS) payload = { "message": f"Upload {filename}", "content": base64.b64encode(content.encode()).decode(), "branch": BRANCH } if r.status_code == 200: payload["sha"] = r.json()["sha"] res = requests.put(url, headers=HEADERS, json=payload) if res.status_code not in (200, 201): raise RuntimeError(f"Upload failed: {res.text}") print(f"âœ… Uploaded/Overwritten: {filename}") def delete_old_files(prefix, keep_filename): """Delete old files with a given prefix, keeping only the specified file""" url = f"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents" r = requests.get(url, headers=HEADERS, params={"ref": BRANCH}) r.raise_for_status() deleted_count = 0 for f in r.json(): name = f["name"] if name.startswith(prefix) and name.endswith(".csv") and name != keep_filename: del_payload = { "message": f"Delete old file {name}", "sha": f["sha"], "branch": BRANCH } del_url = f"{url}/{name}" res = requests.delete(del_url, headers=HEADERS, json=del_payload) if res.status_code == 200: print(f"ğŸ—‘ï¸ Deleted: {name}") deleted_count += 1 else: print(f"âš ï¸ Failed to delete {name}: {res.text}") if deleted_count == 0: print(f"â„¹ï¸ No old files to delete") # ============================================================================ # DATA FETCHING # ============================================================================ def fetch_latest_data_file(prefix='espen_2026'): """Fetch the latest data file from GitHub based on date in filename""" api_url = f'https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/' response = requests.get(api_url, headers=HEADERS) if response.status_code != 200: raise ValueError(f"Failed to fetch repo contents: {response.text}") data = response.json() # Filter files starting with prefix matching_files = [] for item in data: if item['type'] == 'file' and item['name'].startswith(prefix): try: # Extract date from filename, e.g., 'espen_2026-01-15.csv' -> '2026-01-15' date_str = item['name'].split('_'